{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and using models from three notebooks\n",
    "\n",
    "**1.** Deberta v3 large (0.8392)\n",
    "> [Inference BERT for usPatents](https://www.kaggle.com/code/leehann/inference-bert-for-uspatents)\n",
    "\n",
    "**2.** Deberta v3 large (0.8338)\n",
    "> [PPPM / Deberta-v3-large baseline [inference]](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-inference)\n",
    "\n",
    "**3.** Roberta-large (0.8143)\n",
    "> [PatentPhrase RoBERTa Inference](https://www.kaggle.com/code/santhoshkumarv/patentphrase-roberta-inference-lb-0-814)\n",
    "\n",
    "#### Please upvote the original notebooks!\n",
    "\n",
    "##  (Version 1)!\n",
    "\n",
    "Method merge in model 1 shuffled the dataframe.\n",
    "\n",
    "```\n",
    "test = test.merge(titles, left_on='context', right_on='code')\n",
    "```\n",
    "\n",
    "So I reseted index, merged, sorted and drop index.\n",
    "\n",
    "```\n",
    "test.reset_index(inplace=True)\n",
    "test = test.merge(titles, left_on='context', right_on='code')\n",
    "test.sort_values(by='index', inplace=True)\n",
    "test.drop(columns='index', inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import & Def & Set & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-06-20T04:16:15.474776Z",
     "iopub.status.busy": "2022-06-20T04:16:15.474431Z",
     "iopub.status.idle": "2022-06-20T04:16:22.657094Z",
     "shell.execute_reply": "2022-06-20T04:16:22.65639Z",
     "shell.execute_reply.started": "2022-06-20T04:16:15.474698Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, AutoModel\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-06-20T04:16:22.659015Z",
     "iopub.status.busy": "2022-06-20T04:16:22.658773Z",
     "iopub.status.idle": "2022-06-20T04:16:22.670014Z",
     "shell.execute_reply": "2022-06-20T04:16:22.669211Z",
     "shell.execute_reply.started": "2022-06-20T04:16:22.658988Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True    \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    \n",
    "def inference_fn(test_loader, model, device, is_sigmoid=True):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    \n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            output = model(inputs)\n",
    "        \n",
    "        if is_sigmoid == True:\n",
    "            preds.append(output.sigmoid().to('cpu').numpy())\n",
    "        else:\n",
    "            preds.append(output.to('cpu').numpy())\n",
    "\n",
    "    return np.concatenate(preds)    \n",
    "    \n",
    "\n",
    "def upd_outputs(data, is_trim=False, is_minmax=False, is_reshape=False):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    \n",
    "    if is_trim == True:\n",
    "        data = np.where(data <=0, 0, data)\n",
    "        data = np.where(data >=1, 1, data)\n",
    "\n",
    "    if is_minmax ==True:\n",
    "        data = min_max_scaler.fit_transform(data)\n",
    "    \n",
    "    if is_reshape == True:\n",
    "        data = data.reshape(-1)\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:16:22.672163Z",
     "iopub.status.busy": "2022-06-20T04:16:22.67169Z",
     "iopub.status.idle": "2022-06-20T04:16:22.734693Z",
     "shell.execute_reply": "2022-06-20T04:16:22.733817Z",
     "shell.execute_reply.started": "2022-06-20T04:16:22.672128Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 4)\n",
    "cm = sns.light_palette('green', as_cmap=True)\n",
    "props_param = \"color:white; font-weight:bold; background-color:green;\"\n",
    "\n",
    "CUSTOM_SEED = 42\n",
    "CUSTOM_BATCH = 24\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:16:22.737504Z",
     "iopub.status.busy": "2022-06-20T04:16:22.737231Z",
     "iopub.status.idle": "2022-06-20T04:16:22.767946Z",
     "shell.execute_reply": "2022-06-20T04:16:22.767192Z",
     "shell.execute_reply.started": "2022-06-20T04:16:22.73747Z"
    }
   },
   "outputs": [],
   "source": [
    "competition_dir = \"../input/us-patent-phrase-to-phrase-matching/\"\n",
    "\n",
    "submission = pd.read_csv(competition_dir+'sample_submission.csv')\n",
    "test_origin = pd.read_csv(competition_dir+'test.csv')\n",
    "test_origin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract predictions\n",
    "\n",
    "## 2.1 Deberta v3 large - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-06-20T04:16:22.769774Z",
     "iopub.status.busy": "2022-06-20T04:16:22.769163Z",
     "iopub.status.idle": "2022-06-20T04:16:22.780057Z",
     "shell.execute_reply": "2022-06-20T04:16:22.77939Z",
     "shell.execute_reply.started": "2022-06-20T04:16:22.769748Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer(text,\n",
    "                           max_length=cfg.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           truncation=True)\n",
    "    \n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "        \n",
    "    return inputs\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg        \n",
    "        self.text = df['text'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.text[item])\n",
    "        \n",
    "        return inputs\n",
    "   \n",
    "    \n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super().__init__()\n",
    "        \n",
    "        config = AutoConfig.from_pretrained(model_path)\n",
    "        config.num_labels = 1\n",
    "        self.base = AutoModelForSequenceClassification.from_config(config=config)\n",
    "        dim = config.hidden_size\n",
    "        self.dropout = nn.Dropout(p=0)\n",
    "        self.cls = nn.Linear(dim,1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        output = self.base(**inputs)\n",
    "\n",
    "        return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:16:22.781384Z",
     "iopub.status.busy": "2022-06-20T04:16:22.781126Z",
     "iopub.status.idle": "2022-06-20T04:16:22.789927Z",
     "shell.execute_reply": "2022-06-20T04:16:22.789316Z",
     "shell.execute_reply.started": "2022-06-20T04:16:22.781333Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_everything(CUSTOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:16:22.792017Z",
     "iopub.status.busy": "2022-06-20T04:16:22.791757Z",
     "iopub.status.idle": "2022-06-20T04:16:23.506416Z",
     "shell.execute_reply": "2022-06-20T04:16:23.505704Z",
     "shell.execute_reply.started": "2022-06-20T04:16:22.791973Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_path='../input/deberta-v3-large/deberta-v3-large'\n",
    "    batch_size=CUSTOM_BATCH\n",
    "    num_workers=2\n",
    "    max_len=130\n",
    "    trn_fold=[0, 1, 2, 3]\n",
    "\n",
    "CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)\n",
    "\n",
    "context_mapping = torch.load(\"../input/folds-dump-the-two-paths-fix/cpc_texts.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:16:23.507876Z",
     "iopub.status.busy": "2022-06-20T04:16:23.507639Z",
     "iopub.status.idle": "2022-06-20T04:16:24.327951Z",
     "shell.execute_reply": "2022-06-20T04:16:24.32723Z",
     "shell.execute_reply.started": "2022-06-20T04:16:23.507843Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test_origin.copy()\n",
    "titles = pd.read_csv('../input/cpc-codes/titles.csv')\n",
    "\n",
    "test.reset_index(inplace=True)\n",
    "test = test.merge(titles, left_on='context', right_on='code')\n",
    "test.sort_values(by='index', inplace=True)\n",
    "test.drop(columns='index', inplace=True)\n",
    "\n",
    "test['context_text'] = test['context'].map(context_mapping)\n",
    "test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n",
    "test['text'] = test['text'].apply(str.lower)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:16:24.331531Z",
     "iopub.status.busy": "2022-06-20T04:16:24.329047Z",
     "iopub.status.idle": "2022-06-20T04:18:24.282046Z",
     "shell.execute_reply": "2022-06-20T04:18:24.281212Z",
     "shell.execute_reply.started": "2022-06-20T04:16:24.331492Z"
    }
   },
   "outputs": [],
   "source": [
    "deberta_predicts_1 = []\n",
    "\n",
    "test_dataset = TestDataset(CFG, test)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=CFG.batch_size, shuffle=False,\n",
    "                             num_workers=CFG.num_workers,\n",
    "                             pin_memory=True, drop_last=False)\n",
    "\n",
    "deberta_simple_path = \"../input/us-patent-deberta-simple/microsoft_deberta-v3-large\"\n",
    "\n",
    "for fold in CFG.trn_fold:\n",
    "    fold_path = f\"{deberta_simple_path}_best{fold}.pth\"\n",
    "    \n",
    "    model = CustomModel(CFG.model_path)    \n",
    "    state = torch.load(fold_path, map_location=torch.device('cpu'))  # DEVICE\n",
    "    model.load_state_dict(state['model'])\n",
    "    \n",
    "    prediction = inference_fn(test_dataloader, model, DEVICE, is_sigmoid=False)\n",
    "    \n",
    "    deberta_predicts_1.append(prediction)\n",
    "    \n",
    "    del model, state, prediction\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:18:24.285521Z",
     "iopub.status.busy": "2022-06-20T04:18:24.285279Z",
     "iopub.status.idle": "2022-06-20T04:18:24.363888Z",
     "shell.execute_reply": "2022-06-20T04:18:24.363261Z",
     "shell.execute_reply.started": "2022-06-20T04:18:24.285488Z"
    }
   },
   "outputs": [],
   "source": [
    "# -------------- inference_fn([...], is_sigmoid=False)\n",
    "deberta_predicts_1 = [upd_outputs(x, is_minmax=True, is_reshape=True) for x in deberta_predicts_1]\n",
    "deberta_predicts_1 = pd.DataFrame(deberta_predicts_1).T\n",
    "\n",
    "deberta_predicts_1.head(10).style.background_gradient(cmap=cm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:18:24.365327Z",
     "iopub.status.busy": "2022-06-20T04:18:24.365101Z",
     "iopub.status.idle": "2022-06-20T04:18:24.519162Z",
     "shell.execute_reply": "2022-06-20T04:18:24.518491Z",
     "shell.execute_reply.started": "2022-06-20T04:18:24.365296Z"
    }
   },
   "outputs": [],
   "source": [
    "del test, test_dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Deberta v3 large - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-06-20T04:18:24.521152Z",
     "iopub.status.busy": "2022-06-20T04:18:24.520664Z",
     "iopub.status.idle": "2022-06-20T04:18:24.538907Z",
     "shell.execute_reply": "2022-06-20T04:18:24.538093Z",
     "shell.execute_reply.started": "2022-06-20T04:18:24.521114Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer(text,\n",
    "                           add_special_tokens=True,\n",
    "                           max_length=cfg.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)\n",
    "    \n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "        \n",
    "    return inputs\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.texts[item])\n",
    "        return inputs\n",
    "\n",
    "    \n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "            \n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        self._init_weights(self.fc)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self._init_weights(self.attention)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        \n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:18:24.540637Z",
     "iopub.status.busy": "2022-06-20T04:18:24.540062Z",
     "iopub.status.idle": "2022-06-20T04:18:24.549972Z",
     "shell.execute_reply": "2022-06-20T04:18:24.549264Z",
     "shell.execute_reply.started": "2022-06-20T04:18:24.5406Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_everything(CUSTOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:18:24.551172Z",
     "iopub.status.busy": "2022-06-20T04:18:24.55099Z",
     "iopub.status.idle": "2022-06-20T04:18:25.257335Z",
     "shell.execute_reply": "2022-06-20T04:18:25.256588Z",
     "shell.execute_reply.started": "2022-06-20T04:18:24.55115Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    num_workers=2\n",
    "    path=\"../input/pppm-deberta-v3-large-baseline-w-w-b-train/\"\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"microsoft/deberta-v3-large\"\n",
    "    batch_size=CUSTOM_BATCH\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=133\n",
    "    trn_fold=[0, 1, 2, 3]\n",
    "    \n",
    "CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n",
    "\n",
    "context_mapping = torch.load(CFG.path+\"cpc_texts.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:18:25.259002Z",
     "iopub.status.busy": "2022-06-20T04:18:25.258749Z",
     "iopub.status.idle": "2022-06-20T04:18:25.275285Z",
     "shell.execute_reply": "2022-06-20T04:18:25.2745Z",
     "shell.execute_reply.started": "2022-06-20T04:18:25.258971Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test_origin.copy()\n",
    "\n",
    "test['context_text'] = test['context'].map(context_mapping)\n",
    "test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:18:25.277012Z",
     "iopub.status.busy": "2022-06-20T04:18:25.276753Z",
     "iopub.status.idle": "2022-06-20T04:20:08.757078Z",
     "shell.execute_reply": "2022-06-20T04:20:08.756189Z",
     "shell.execute_reply.started": "2022-06-20T04:18:25.276978Z"
    }
   },
   "outputs": [],
   "source": [
    "deberta_predicts_2 = []\n",
    "\n",
    "test_dataset = TestDataset(CFG, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG.num_workers,\n",
    "                         pin_memory=True, drop_last=False)\n",
    "\n",
    "folds_path = CFG.path + f\"{CFG.model.replace('/', '-')}\"\n",
    "\n",
    "for fold in CFG.trn_fold:\n",
    "    fold_path = f\"{folds_path}_fold{fold}_best.pth\"\n",
    "    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n",
    "    state = torch.load(fold_path, map_location=torch.device('cpu'))  # DEVICE\n",
    "    model.load_state_dict(state['model'])\n",
    "    \n",
    "    prediction = inference_fn(test_loader, model, DEVICE)\n",
    "    deberta_predicts_2.append(prediction)\n",
    "    \n",
    "    del model, state, prediction\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:20:08.759105Z",
     "iopub.status.busy": "2022-06-20T04:20:08.758823Z",
     "iopub.status.idle": "2022-06-20T04:20:08.791137Z",
     "shell.execute_reply": "2022-06-20T04:20:08.790298Z",
     "shell.execute_reply.started": "2022-06-20T04:20:08.759064Z"
    }
   },
   "outputs": [],
   "source": [
    "deberta_predicts_2 = [upd_outputs(x, is_reshape=True) for x in deberta_predicts_2]\n",
    "deberta_predicts_2 = pd.DataFrame(deberta_predicts_2).T\n",
    "\n",
    "deberta_predicts_2.head(10).style.background_gradient(cmap=cm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:20:08.792942Z",
     "iopub.status.busy": "2022-06-20T04:20:08.792656Z",
     "iopub.status.idle": "2022-06-20T04:20:08.965733Z",
     "shell.execute_reply": "2022-06-20T04:20:08.964848Z",
     "shell.execute_reply.started": "2022-06-20T04:20:08.792911Z"
    }
   },
   "outputs": [],
   "source": [
    "del test, test_dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-06-20T04:20:08.967734Z",
     "iopub.status.busy": "2022-06-20T04:20:08.967478Z",
     "iopub.status.idle": "2022-06-20T04:20:08.984218Z",
     "shell.execute_reply": "2022-06-20T04:20:08.983244Z",
     "shell.execute_reply.started": "2022-06-20T04:20:08.967701Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_input(cfg, text, target):\n",
    "    inputs = cfg.tokenizer(text, target,\n",
    "                           padding=\"max_length\",\n",
    "                           max_length=cfg.max_len,\n",
    "                           truncation=True)\n",
    "\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "        \n",
    "    return inputs\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "        self.target = df['target'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = self.texts[item]\n",
    "        target = self.target[item]\n",
    "        \n",
    "        inputs = prepare_input(self.cfg, text, target)\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "    \n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        hidden_dropout_prob: float = 0.1\n",
    "        layer_norm_eps: float = 1e-7\n",
    "\n",
    "        config = AutoConfig.from_pretrained(CFG.config_path)\n",
    "\n",
    "        config.update({\"output_hidden_states\": True,\n",
    "                       \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                       \"layer_norm_eps\": layer_norm_eps,\n",
    "                       \"add_pooling_layer\": False})\n",
    "        \n",
    "        self.transformer = AutoModel.from_pretrained(CFG.config_path, config=config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.dropout4 = nn.Dropout(0.4)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        self.output = nn.Linear(config.hidden_size, CFG.num_targets)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        transformer_out = self.transformer(**inputs)\n",
    "        last_hidden_states = transformer_out[0]\n",
    "        last_hidden_states = self.dropout(torch.mean(last_hidden_states, 1))\n",
    "        logits1 = self.output(self.dropout1(last_hidden_states))\n",
    "        logits2 = self.output(self.dropout2(last_hidden_states))\n",
    "        logits3 = self.output(self.dropout3(last_hidden_states))\n",
    "        logits4 = self.output(self.dropout4(last_hidden_states))\n",
    "        logits5 = self.output(self.dropout5(last_hidden_states))\n",
    "        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:20:08.986538Z",
     "iopub.status.busy": "2022-06-20T04:20:08.985672Z",
     "iopub.status.idle": "2022-06-20T04:20:08.994527Z",
     "shell.execute_reply": "2022-06-20T04:20:08.993791Z",
     "shell.execute_reply.started": "2022-06-20T04:20:08.9865Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_everything(CUSTOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:20:08.996249Z",
     "iopub.status.busy": "2022-06-20T04:20:08.99598Z",
     "iopub.status.idle": "2022-06-20T04:20:09.260864Z",
     "shell.execute_reply": "2022-06-20T04:20:09.260133Z",
     "shell.execute_reply.started": "2022-06-20T04:20:08.996201Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class CFG:\n",
    "    num_workers=2\n",
    "    config_path='../input/robertalarge'\n",
    "    model_path='../input/phrase-matching-roberta-training-pytorch-wandb'\n",
    "    model_name='roberta-large'\n",
    "    batch_size=CUSTOM_BATCH\n",
    "    max_len=128\n",
    "    num_targets=1\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    tokenizer=AutoTokenizer.from_pretrained('../input/robertalarge')\n",
    "\n",
    "context_mapping = {\n",
    "        \"A\": \"Human Necessities\",\n",
    "        \"B\": \"Operations and Transport\",\n",
    "        \"C\": \"Chemistry and Metallurgy\",\n",
    "        \"D\": \"Textiles\",\n",
    "        \"E\": \"Fixed Constructions\",\n",
    "        \"F\": \"Mechanical Engineering\",\n",
    "        \"G\": \"Physics\",\n",
    "        \"H\": \"Electricity\",\n",
    "        \"Y\": \"Emerging Cross-Sectional Technologies\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:20:09.262483Z",
     "iopub.status.busy": "2022-06-20T04:20:09.262221Z",
     "iopub.status.idle": "2022-06-20T04:20:09.270134Z",
     "shell.execute_reply": "2022-06-20T04:20:09.269197Z",
     "shell.execute_reply.started": "2022-06-20T04:20:09.262449Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test_origin.copy()\n",
    "\n",
    "test['context_text'] = test['context'].str.slice(stop=1).map(context_mapping)\n",
    "test['text'] = test['context_text'] + ' ' + test['anchor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:20:09.271932Z",
     "iopub.status.busy": "2022-06-20T04:20:09.271488Z",
     "iopub.status.idle": "2022-06-20T04:20:09.286595Z",
     "shell.execute_reply": "2022-06-20T04:20:09.285764Z",
     "shell.execute_reply.started": "2022-06-20T04:20:09.271895Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-06-20T04:20:09.288964Z",
     "iopub.status.busy": "2022-06-20T04:20:09.288096Z",
     "iopub.status.idle": "2022-06-20T04:21:55.220004Z",
     "shell.execute_reply": "2022-06-20T04:21:55.219194Z",
     "shell.execute_reply.started": "2022-06-20T04:20:09.28892Z"
    }
   },
   "outputs": [],
   "source": [
    "roberta_predicts = []\n",
    "\n",
    "test_dataset = TestDataset(CFG, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG.num_workers,\n",
    "                         pin_memory=True, drop_last=False)\n",
    "\n",
    "folds_path = CFG.model_path + f\"/{CFG.model_name.replace('-','_')}\"\n",
    "\n",
    "for fold in CFG.trn_fold:\n",
    "    fold_path = f\"{folds_path}_patent_model_{fold}.pth\"\n",
    "    \n",
    "    model = CustomModel()\n",
    "    state = torch.load(fold_path, map_location=torch.device('cpu'))  # DEVICE\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    prediction = inference_fn(test_loader, model, DEVICE)\n",
    "    roberta_predicts.append(prediction)\n",
    "    \n",
    "    del model, state, prediction\n",
    "    torch.cuda.empty_cache()    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:21:55.221959Z",
     "iopub.status.busy": "2022-06-20T04:21:55.221651Z",
     "iopub.status.idle": "2022-06-20T04:21:55.249939Z",
     "shell.execute_reply": "2022-06-20T04:21:55.249254Z",
     "shell.execute_reply.started": "2022-06-20T04:21:55.221917Z"
    }
   },
   "outputs": [],
   "source": [
    "roberta_predicts = [upd_outputs(x, is_reshape=True) for x in roberta_predicts]\n",
    "roberta_predicts = pd.DataFrame(roberta_predicts).T\n",
    "\n",
    "roberta_predicts.head(10).style.background_gradient(cmap=cm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:21:55.251331Z",
     "iopub.status.busy": "2022-06-20T04:21:55.251021Z",
     "iopub.status.idle": "2022-06-20T04:21:55.41321Z",
     "shell.execute_reply": "2022-06-20T04:21:55.412378Z",
     "shell.execute_reply.started": "2022-06-20T04:21:55.251295Z"
    }
   },
   "outputs": [],
   "source": [
    "del test, test_dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Comparison / Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:21:55.415406Z",
     "iopub.status.busy": "2022-06-20T04:21:55.414835Z",
     "iopub.status.idle": "2022-06-20T04:21:55.499894Z",
     "shell.execute_reply": "2022-06-20T04:21:55.49922Z",
     "shell.execute_reply.started": "2022-06-20T04:21:55.415369Z"
    }
   },
   "outputs": [],
   "source": [
    "all_predictions = pd.concat(\n",
    "    [deberta_predicts_1, deberta_predicts_2, roberta_predicts],\n",
    "    keys=['deberta 1', 'deberta 2', 'roberta'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "all_predictions.head(10) \\\n",
    "    .assign(mean=lambda x: x.mean(axis=1)) \\\n",
    "        .style.background_gradient(cmap=cm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:21:55.504488Z",
     "iopub.status.busy": "2022-06-20T04:21:55.503701Z",
     "iopub.status.idle": "2022-06-20T04:21:55.523519Z",
     "shell.execute_reply": "2022-06-20T04:21:55.522843Z",
     "shell.execute_reply.started": "2022-06-20T04:21:55.504447Z"
    }
   },
   "outputs": [],
   "source": [
    "all_mean = pd.DataFrame({\n",
    "    'deberta 1': deberta_predicts_1.mean(axis=1),\n",
    "    'deberta 2': deberta_predicts_2.mean(axis=1),\n",
    "    'roberta': roberta_predicts.mean(axis=1)\n",
    "})\n",
    "\n",
    "all_mean.head(10) \\\n",
    "    .assign(mean=lambda x: x.mean(axis=1)) \\\n",
    "        .style.highlight_max(axis=1, props=props_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:21:55.525313Z",
     "iopub.status.busy": "2022-06-20T04:21:55.524642Z",
     "iopub.status.idle": "2022-06-20T04:21:55.536389Z",
     "shell.execute_reply": "2022-06-20T04:21:55.535607Z",
     "shell.execute_reply.started": "2022-06-20T04:21:55.525276Z"
    }
   },
   "outputs": [],
   "source": [
    "# === N1 ===\n",
    "# weights_ = [0.33, 0.33, 0.33]\n",
    "# final_predictions = all_mean.mul(weights_).sum(axis=1)\n",
    "\n",
    "# === N2 ===\n",
    "# final_predictions = all_mean.median(axis=1)\n",
    "final_predictions = all_mean.mean(axis=1)\n",
    "\n",
    "# === N3 ===\n",
    "# final_predictions = all_predictions.mean(axis=1)\n",
    "\n",
    "# === N4 ===\n",
    "# combs = pd.DataFrame({\n",
    "#     'deberta_1': deberta_predicts_1.mean(axis=1),\n",
    "#     'deb_2+rob': (deberta_predicts_2.mean(axis=1) * 0.666) \\\n",
    "#                     + (roberta_predicts.mean(axis=1) * 0.333)\n",
    "# })\n",
    "# display(combs.head())\n",
    "# final_predictions = combs.median(axis=1)\n",
    "# final_predictions = combs.mean(axis=1)\n",
    "\n",
    "final_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:21:55.538623Z",
     "iopub.status.busy": "2022-06-20T04:21:55.538082Z",
     "iopub.status.idle": "2022-06-20T04:21:55.550669Z",
     "shell.execute_reply": "2022-06-20T04:21:55.549899Z",
     "shell.execute_reply.started": "2022-06-20T04:21:55.538585Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': test_origin['id'],\n",
    "    'score': final_predictions,\n",
    "})\n",
    "\n",
    "submission.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:21:55.552326Z",
     "iopub.status.busy": "2022-06-20T04:21:55.552078Z",
     "iopub.status.idle": "2022-06-20T04:21:55.555704Z",
     "shell.execute_reply": "2022-06-20T04:21:55.554992Z",
     "shell.execute_reply.started": "2022-06-20T04:21:55.552294Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===================  Baseline\n",
    "# 0  4112d61851461f60  0.56127\n",
    "# 1  09e418c93a776564  0.72176\n",
    "# 2  36baf228038e314b  0.47086\n",
    "# 3  1f37ead645e7f0c8  0.25826\n",
    "# 4  71a5b6ad068d531f  0.00908\n",
    "# 5  474c874d0c07bd21  0.48173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T04:21:55.557689Z",
     "iopub.status.busy": "2022-06-20T04:21:55.557171Z",
     "iopub.status.idle": "2022-06-20T04:21:55.56778Z",
     "shell.execute_reply": "2022-06-20T04:21:55.56704Z",
     "shell.execute_reply.started": "2022-06-20T04:21:55.557651Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
